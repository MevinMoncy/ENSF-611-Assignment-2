{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92778525",
   "metadata": {},
   "source": [
    "# Assignment 2: Linear Models and Validation Metrics (30 marks total)\n",
    "### Due: October 10 at 11:59pm\n",
    "\n",
    "### Name: Mevin Moncy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce31b39a",
   "metadata": {},
   "source": [
    "### In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c6de86",
   "metadata": {},
   "source": [
    "## Part 1: Classification (14.5 marks total)\n",
    "\n",
    "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3c6fc8",
   "metadata": {},
   "source": [
    "### Step 0: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f86925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9d33a8",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
    "\n",
    "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33583c67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4600, 57)\n",
      "(4600,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n",
      "\n",
      "word_freq_make                float64\n",
      "word_freq_address             float64\n",
      "word_freq_all                 float64\n",
      "word_freq_3d                  float64\n",
      "word_freq_our                 float64\n",
      "word_freq_over                float64\n",
      "word_freq_remove              float64\n",
      "word_freq_internet            float64\n",
      "word_freq_order               float64\n",
      "word_freq_mail                float64\n",
      "word_freq_receive             float64\n",
      "word_freq_will                float64\n",
      "word_freq_people              float64\n",
      "word_freq_report              float64\n",
      "word_freq_addresses           float64\n",
      "word_freq_free                float64\n",
      "word_freq_business            float64\n",
      "word_freq_email               float64\n",
      "word_freq_you                 float64\n",
      "word_freq_credit              float64\n",
      "word_freq_your                float64\n",
      "word_freq_font                float64\n",
      "word_freq_000                 float64\n",
      "word_freq_money               float64\n",
      "word_freq_hp                  float64\n",
      "word_freq_hpl                 float64\n",
      "word_freq_george              float64\n",
      "word_freq_650                 float64\n",
      "word_freq_lab                 float64\n",
      "word_freq_labs                float64\n",
      "word_freq_telnet              float64\n",
      "word_freq_857                 float64\n",
      "word_freq_data                float64\n",
      "word_freq_415                 float64\n",
      "word_freq_85                  float64\n",
      "word_freq_technology          float64\n",
      "word_freq_1999                float64\n",
      "word_freq_parts               float64\n",
      "word_freq_pm                  float64\n",
      "word_freq_direct              float64\n",
      "word_freq_cs                  float64\n",
      "word_freq_meeting             float64\n",
      "word_freq_original            float64\n",
      "word_freq_project             float64\n",
      "word_freq_re                  float64\n",
      "word_freq_edu                 float64\n",
      "word_freq_table               float64\n",
      "word_freq_conference          float64\n",
      "char_freq_;                   float64\n",
      "char_freq_(                   float64\n",
      "char_freq_[                   float64\n",
      "char_freq_!                   float64\n",
      "char_freq_$                   float64\n",
      "char_freq_#                   float64\n",
      "capital_run_length_average    float64\n",
      "capital_run_length_longest      int64\n",
      "capital_run_length_total        int64\n",
      "dtype: object\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "\n",
    "\n",
    "from yellowbrick.datasets import load_spam\n",
    "import mglearn\n",
    "import yellowbrick\n",
    "\n",
    "X,y = load_spam()\n",
    "\n",
    "# TO DO: Print size and type of X and y\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "print()\n",
    "\n",
    "print(X.dtypes)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156db208",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (1.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e7204f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "\n",
    "missing_values_X = X.isnull().sum().sum()\n",
    "missing_values_y = y.isnull().sum().sum()\n",
    "\n",
    "print(missing_values_X)\n",
    "print(missing_values_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a489285a",
   "metadata": {},
   "source": [
    "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9bc4a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: Create X_small and y_small \n",
    "from sklearn.model_selection import train_test_split #splits training and testing sets, x IS DEATURE, Y IS TARGET, X_small,ymall is the training\n",
    "\n",
    "X_small, X_val, y_small, y_val = train_test_split(X, y,train_size=0.05, random_state=0)\n",
    "X_small_a, X_val_a, y_small_a, y_val_a = train_test_split(X_small, y_small, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c46f",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model\n",
    "\n",
    "1. Import `LogisticRegression` from sklearn\n",
    "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
    "3. Implement the machine learning model with three different datasets: \n",
    "    - `X` and `y`\n",
    "    - Only first two columns of `X` and `y`\n",
    "    - `X_small` and `y_small`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a139027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "#Spliting into three datasets:\n",
    "\n",
    "## X & y\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "model_logreg = LogisticRegression(max_iter=2000).fit(X_train, y_train)\n",
    "\n",
    "# Only first two columns of X and y\n",
    "X_train_partial, X_val_partial, y_train_partial, y_val_partial = train_test_split(X.iloc[:, :2], y, random_state=0)\n",
    "model_partial = LogisticRegression(max_iter=2000).fit(X_train_partial, y_train_partial)\n",
    "\n",
    "# X_small and y_small\n",
    "X_small, X_val_small, y_small, y_val_small = train_test_split(X, y, train_size=0.05, random_state=0)\n",
    "X_small_a, X_val_a, y_small_a, y_val_a = train_test_split(X_small, y_small, random_state=0)\n",
    "model_small = LogisticRegression(max_iter=2000).fit(X_small_a, y_small_a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89f3d84",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model\n",
    "\n",
    "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "659a5227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score for X & y: 0.928\n",
      "Validation set score for X & y: 0.938\n",
      "\n",
      "Training set score for partial X & y: 0.608\n",
      "Validation set score for partial X & y: 0.613\n",
      "\n",
      "Training set score for small X & y: 0.936\n",
      "Validation set score for small X & y: 0.931\n"
     ]
    }
   ],
   "source": [
    "## X & y\n",
    "model_logreg_training = model_logreg.score(X_train, y_train)\n",
    "model_logreg_val = model_logreg.score(X_val, y_val)\n",
    "print(f\"Training set score for X & y: {model_logreg_training:.3f}\")\n",
    "print(f\"Validation set score for X & y: {model_logreg_val:.3f}\")\n",
    "print()\n",
    "\n",
    "# Only first two columns of X and y\n",
    "model_partial_training = model_partial.score(X_train_partial, y_train_partial)\n",
    "model_partial_val = model_partial.score(X_val_partial, y_val_partial)\n",
    "print(f\"Training set score for partial X & y: {model_partial_training:.3f}\")\n",
    "print(f\"Validation set score for partial X & y: {model_partial_val:.3f}\")\n",
    "print()\n",
    "\n",
    "# X_small and y_small\n",
    "model_small_training = model_small.score(X_small_a, y_small_a)\n",
    "model_small_val = model_small.score(X_val_a, y_val_a)\n",
    "print(f\"Training set score for small X & y: {model_small_training:.3f}\")\n",
    "print(f\"Validation set score for small X & y: {model_small_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352106a3",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (4 marks)\n",
    "\n",
    "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
    "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4b5c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score for X & y: 0.928\n",
      "Validation set score for X & y: 0.938\n",
      "\n",
      "Training set score for partial X & y: 0.608\n",
      "Validation set score for partial X & y: 0.613\n",
      "\n",
      "Training set score for small X & y: 0.936\n",
      "Validation set score for small X & y: 0.931\n",
      "\n",
      "   Data Size  Training accuracy  Validation accuracy\n",
      "0   262200.0              0.928                0.938\n",
      "1     9200.0              0.608                0.613\n",
      "2    13110.0              0.936                0.931\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE FOR STEPS 3-5\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
    "\n",
    "#####------------Implement ML Model\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=2000)\n",
    "\n",
    "#Spliting into three datasets:\n",
    "\n",
    "## X & y\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "model_logreg = LogisticRegression(max_iter=2000).fit(X_train, y_train)\n",
    "\n",
    "# Only first two columns of X and y\n",
    "X_train_partial, X_val_partial, y_train_partial, y_val_partial = train_test_split(X.iloc[:, :2], y, random_state=0)\n",
    "model_partial = LogisticRegression(max_iter=2000).fit(X_train_partial, y_train_partial)\n",
    "\n",
    "# X_small and y_small\n",
    "X_small, X_val_small, y_small, y_val_small = train_test_split(X, y, train_size=0.05, random_state=0)\n",
    "X_small_a, X_val_a, y_small_a, y_val_a = train_test_split(X_small, y_small, random_state=0)\n",
    "model_small = LogisticRegression(max_iter=2000).fit(X_small_a, y_small_a)\n",
    "\n",
    "\n",
    "#### -------------Validation model\n",
    "## X & y\n",
    "model_logreg_training = model_logreg.score(X_train, y_train)\n",
    "model_logreg_val = model_logreg.score(X_val, y_val)\n",
    "print(f\"Training set score for X & y: {model_logreg_training:.3f}\")\n",
    "print(f\"Validation set score for X & y: {model_logreg_val:.3f}\")\n",
    "print()\n",
    "\n",
    "# Only first two columns of X and y\n",
    "model_partial_training = model_partial.score(X_train_partial, y_train_partial)\n",
    "model_partial_val = model_partial.score(X_val_partial, y_val_partial)\n",
    "print(f\"Training set score for partial X & y: {model_partial_training:.3f}\")\n",
    "print(f\"Validation set score for partial X & y: {model_partial_val:.3f}\")\n",
    "print()\n",
    "\n",
    "# X_small and y_small\n",
    "model_small_training = model_small.score(X_small_a, y_small_a)\n",
    "model_small_val = model_small.score(X_val_a, y_val_a)\n",
    "print(f\"Training set score for small X & y: {model_small_training:.3f}\")\n",
    "print(f\"Validation set score for small X & y: {model_small_val:.3f}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "##----------------\n",
    "\n",
    "results = pd.DataFrame(columns = [\"Data Size\", \"Training accuracy\", \"Validation accuracy\"])\n",
    "\n",
    "results.loc[0] = [X.size, model_logreg_training, model_logreg_val]\n",
    "results.loc[1] = [X.iloc[:,:2].size, model_partial_training, model_partial_val]\n",
    "results.loc[2] = [X_small.size, model_small_training,model_small_val]\n",
    "\n",
    "print(results.round(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4427d4f",
   "metadata": {},
   "source": [
    "### Questions (4 marks)\n",
    "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
    "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
    "\n",
    "Answer 1:\n",
    "\n",
    "new : When we use the full data sets,with all the features we get training accuracy score of 0.928 and validation score of 0.938. Since they have high scores and close to each other, we can say that the model performed well.\n",
    "\n",
    "As you use less data(ie: parital columns used for X), the training score was 0.608 and validation score was 0.613. From this low scores for both, we see that less features is used to train and this models becomes too simple and underfits. \n",
    "\n",
    "For the small sample size, it has training score of 0.936 and validation score of 0.931, however it has been trained on less data, therefore it could of memorirized it and thus leading to higher training and validation accuracy.\n",
    "\n",
    "-----\n",
    "Answer 2:\n",
    "In this instance false negative is when you get the spam email in your inbox, when it should of been flagged as spam and go to the spam folder.\n",
    "False positive is when a non-spam email is flagged as an spam and it went to the spam folder.\n",
    "\n",
    "False positive is worse in my opinion, because it can be a problem when an imporant email gets flagged as a spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7559517a",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe687f",
   "metadata": {},
   "source": [
    "Answer 1:\n",
    "I used the previous examples we done in class, such as logestic regression, and modified the code as per the question requirements. I also took assistance for the generative AI called ChatGPT. \n",
    "\n",
    "Answer 2:\n",
    "I completed the steps as per the instrustions on this file. I started from Step 0. This was a good way to tackle the problem step by step to understand what is going on.\n",
    "\n",
    "Answer 3:\n",
    "The prompts I used in ChatGPT are \"How did you format the signitficant digits in a f string\". I did not need to modify the code becauase the formatting you have to do it in a certain way. \n",
    "\n",
    "Link: https://chat.openai.com/\n",
    "\n",
    "Answer 4:\n",
    "Initally, I had challenge starting the problem, but I looked at previous examples done on class as reference, and how they implemented the code. It was challenging, but I understood there was a pattern in machine learning model and understanding how to split the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4c78a8",
   "metadata": {},
   "source": [
    "## Part 2: Regression (10.5 marks total)\n",
    "\n",
    "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ba83c5",
   "metadata": {},
   "source": [
    "### Step 1: Data Input (1 mark)\n",
    "\n",
    "The data used for this task can be downloaded using the yellowbrick library: \n",
    "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
    "\n",
    "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
    "\n",
    "Print the size and type of `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ff2e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1030, 8)\n",
      "(1030,)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Import spam dataset from yellowbrick library\n",
    "# TO DO: Print size and type of X and y\n",
    "\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X,y = load_concrete()\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5294cfa",
   "metadata": {},
   "source": [
    "### Step 2: Data Processing (0.5 marks)\n",
    "\n",
    "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "693c5fa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# TO DO: Check if there are any missing values and fill them in if necessary\n",
    "missing_values_X = X.isnull().sum().sum()\n",
    "missing_values_y = y.isnull().sum().sum()\n",
    "\n",
    "print(missing_values_X)\n",
    "print(missing_values_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc60489",
   "metadata": {},
   "source": [
    "### Step 3: Implement Machine Learning Model (1 mark)\n",
    "\n",
    "1. Import `LinearRegression` from sklearn\n",
    "2. Instantiate model `LinearRegression()`.\n",
    "3. Implement the machine learning model with `X` and `y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5041945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "# Note: for any random state parameters, you can use random_state = 0\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de28482",
   "metadata": {},
   "source": [
    "### Step 4: Validate Model (1 mark)\n",
    "\n",
    "Calculate the training and validation accuracy using mean squared error and R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "970c038b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score for Mean Squared Error: 111.36\n",
      "Validation set score for Mean Squared Error: 95.90\n",
      "\n",
      "Training set score for R2 Score: 0.611\n",
      "Validation set score for R2 Score: 0.623\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_val_pred = lr.predict(X_val)\n",
    "\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "\n",
    "\n",
    "print(f\"Training set score for Mean Squared Error: {mse_train:.2f}\")\n",
    "print(f\"Validation set score for Mean Squared Error: {mse_val:.2f}\")\n",
    "print()\n",
    "#-----\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "\n",
    "print(f\"Training set score for R2 Score: {r2_train:.3f}\")\n",
    "print(f\"Validation set score for R2 Score: {r2_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aa7795",
   "metadata": {},
   "source": [
    "### Step 5: Visualize Results (1 mark)\n",
    "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
    "2. Add the accuracy results to the `results` DataFrame\n",
    "3. Print `results`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88d223f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Training accuracy  Validation accuracy\n",
      "Mean Squared Error            111.358               95.904\n",
      "R2 Score                        0.611                0.623\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "results = pd.DataFrame(columns=[\"Training accuracy\", \"Validation accuracy\"], index=[\"Mean Squared Error\", \"R2 Score\"])\n",
    "results[\"Training accuracy\"] = [mse_train, r2_train]\n",
    "results[\"Validation accuracy\"] = [mse_val, r2_val]\n",
    "\n",
    "print(results.round(3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a42bda",
   "metadata": {},
   "source": [
    "### Questions (2 marks)\n",
    "1. Did using a linear model produce good results for this dataset? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efc0a85",
   "metadata": {},
   "source": [
    "Answer 1: In the linaear model, the Mean Squared Error(MSE) training score is  111.358, Validation score is 95.904. And for R2 Score training score is 0.611 and Validation score is 0.623.\n",
    "\n",
    "\n",
    "Also R2 scores is way less than 1, where values closer to 1 has a better fit. Both the Training and validation scores are about 60%, therefore the model explains 60% of the variance in the data. This also shows that the models underfits and it is too simple.\n",
    "\n",
    "Therefore, I believe Linear model, did not produce good results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca0ff2f",
   "metadata": {},
   "source": [
    "### Process Description (4 marks)\n",
    "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
    "1. Where did you source your code?\n",
    "1. In what order did you complete the steps?\n",
    "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
    "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdb0880",
   "metadata": {},
   "source": [
    "Answer 1:\n",
    "I used the previous examples we done in class like i mentioned before, such as Linear Regression, and modified the code as per the question requirements. I also took assistance for the generative AI called ChatGPT. \n",
    "\n",
    "Answer 2:\n",
    "I completed the steps as per the instrustions on this file. I started from Step 1. This was a good way to tackle the problem step by step to understand what is going on.\n",
    "\n",
    "Answer 3:\n",
    "The prompts I used in ChatGPT are \"how do you import r2 and mse libraries from sklearn and to calculate the mse and r2 scores\". I did not need to modify the code becauase the formatting you have to do it in a certain way in order to import these libaries. And to calculate the r2 and mse scores, it has to be done from a function call and that you have to do it in a certain way. \n",
    "\n",
    "Link: https://chat.openai.com/\n",
    "\n",
    "Answer 4:\n",
    "Initally, I had challenge of calculating the mse and r2 scores becuase i could not find it from the examples when I looked for reference, but ChatGPT was able to assit me in importing those libraries and how they are clauclated. This has helped me to complete the calculation for mse and r2 scores.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72ac3eb",
   "metadata": {},
   "source": [
    "## Part 3: Observations/Interpretation (3 marks)\n",
    "\n",
    "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
    "\n",
    "\n",
    "In part 1, we can see that when we use only the first two columns, we get the training and validiation scores around 0.6. Since is way less than one it is less accurate model compareded to the full data set and the small data set. This means when you use less data/less features used to train, this models becomes too simple and underfits. \n",
    "\n",
    "For Full data set in part 1, has training score of 0.928 and vaildation score of 0.938. This has slightly worse results than small data (Training score: 0.936 and Validation score:0.931). The small data has been only trained on smaller set of data, so the scores received was higher than original data set for training and validation scores since it has been trained on less data. Therefore, I see that when you give less data to train, it most likely memorizes the data, therefore giving a higher training and validation scores.\n",
    "\n",
    "In Part 2, we see a training score of 0.611 and validation score of 0.623, this shows that it is underfitting in R2 scores. This suggests that the model is not fitting well, and not performing better on the validation data. This could mean high bias and the model may be too simple.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b84eed",
   "metadata": {},
   "source": [
    "## Part 4: Reflection (2 marks)\n",
    "Include a sentence or two about:\n",
    "- what you liked or disliked,\n",
    "- found interesting, confusing, challangeing, motivating\n",
    "while working on this assignment.\n",
    "\n",
    "\n",
    "What I liked about this assignment is that I got a hands on experience to build linear and logestic models. I got to see how these model works and a good learning experience.\n",
    "\n",
    "I found it confusing at first on why we had to do train split on three different data sets for Question 1. But later i understood why we had to do the train split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db951b3a",
   "metadata": {},
   "source": [
    "## Part 5: Bonus Question (4 marks)\n",
    "\n",
    "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
    "\n",
    "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47623d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression - Training set score for Mean Squared Error: 111.36\n",
      "Ridge Regression - Validation set score for Mean Squared Error: 95.90\n",
      "Ridge Regression - Training set score for R2 Score: 0.611\n",
      "Ridge Regression - Validation set score for R2 Score: 0.623\n",
      "\n",
      "Lasso Regression - Training set score for Mean Squared Error: 111.42\n",
      "Lasso Regression - Validation set score for Mean Squared Error: 95.58\n",
      "Lasso Regression - Training set score for R2 Score: 0.611\n",
      "Lasso Regression - Validation set score for R2 Score: 0.625\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TO DO: ADD YOUR CODE HERE\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "from yellowbrick.datasets import load_concrete\n",
    "X,y = load_concrete()\n",
    "\n",
    "\n",
    "##Ridge regression\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "ridge_model = Ridge(alpha= 1).fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = ridge_model.predict(X_train)\n",
    "y_val_pred = ridge_model.predict(X_val)\n",
    "\n",
    "mse_train = mean_squared_error(y_train,y_train_pred)\n",
    "mse_val = mean_squared_error(y_val,y_val_pred)\n",
    "\n",
    "print(f\"Ridge Regression - Training set score for Mean Squared Error: {mse_train:.2f}\")\n",
    "print(f\"Ridge Regression - Validation set score for Mean Squared Error: {mse_val:.2f}\")\n",
    "\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "print(f\"Ridge Regression - Training set score for R2 Score: {r2_train:.3f}\")\n",
    "print(f\"Ridge Regression - Validation set score for R2 Score: {r2_val:.3f}\")\n",
    "print()\n",
    "\n",
    "## Lasso\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)\n",
    "lasso_model = Lasso(alpha= 1).fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = lasso_model.predict(X_train)\n",
    "y_val_pred = lasso_model.predict(X_val)\n",
    "\n",
    "mse_train = mean_squared_error(y_train,y_train_pred)\n",
    "mse_val = mean_squared_error(y_val,y_val_pred)\n",
    "\n",
    "print(f\"Lasso Regression - Training set score for Mean Squared Error: {mse_train:.2f}\")\n",
    "print(f\"Lasso Regression - Validation set score for Mean Squared Error: {mse_val:.2f}\")\n",
    "\n",
    "r2_train = r2_score(y_train, y_train_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "print(f\"Lasso Regression - Training set score for R2 Score: {r2_train:.3f}\")\n",
    "print(f\"Lasso Regression - Validation set score for R2 Score: {r2_val:.3f}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b606236",
   "metadata": {},
   "source": [
    "I got 0.611 for training for both lasso and ridge regression and 0.623 for Ridge regression and 0.625 for Lasso regression.\n",
    "\n",
    "I tried different numbers of alpha numbers, but Alpha number of 1 has the best R2 Square becuause it gave me the highest R2 scores and the one closest to 1. \n",
    "However, the score is not good enough becuase it is not close to 1 and it is further away. \n",
    "\n",
    "It is difficult to say which method performed better becuase all the methods performed gave similar results about 0.611 for training for ridge,lasso, and linear and 0.623 for Ridge regression and linear, and 0.625 for Lasso regression., therefore all the methods used was not useful at all.\n",
    "\n",
    "Since the R2 are low, it indicates the model is underfitting and the objective of lasso and ridge is to regularize the model and reduce overfitting, however, in this case it is not needed and we should try a more complex model.\n",
    "\n",
    "Therefore, I believe the score is  not good enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d131077",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0d1a871",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
